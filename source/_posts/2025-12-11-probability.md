---
layout: post
categories: AI
title: 学会掌控复读机的概率游戏

---

这些年来写文章对我来说，不仅仅是总结、积累的过程，更加是一种强行让自己从消极转变为积极的手段。

### 1. 重塑世界

现在很多人都猜测大模型的发展已经到了尽头。

<br/>

这体现在几个方面

- 虽然各大厂商的 LLM 仍然在更新版本，但是在能力水平上已经趋于相似。边际效用递减，投入多一倍，能力只提升 1%

- LLM 底层原理所致，不可能通向 AGI。LLM 的能力十分受限于样本训练集，也只能对下一个 token 进行预测。「复读机」无法真正的「思考」

- 大家都知道了 AI 不像传说的那样神，有些事情确实不太适合用 AI 解决。说到底是一种概率游戏，要想提升概率就得不断的增加成本

<br/>

但即便如此，基于 LLM 进行「应用层」开发，还远没有到尽头，反而变得越来越火热。

也就是说即使 LLM 能力不再发展了，应用层仍然有太多事情可以做，AI 真的在重塑世界。

<br/>

- 比如说，AI 对编程的影响。前端开发已经习惯使用 Cursor 这类的编程工具了，现在大家想弄明白的，已经是 AI 能提效多少的问题，而不是 AI 能不能提效的问题。这已经完全改变了开发习惯。

- 此外，另一个影响较大的是搜索。不论是开发遇到的问题，还是日常生活，搜索引擎我已经很久没有用过了。日常问题直接问豆包，开发问题直接问 Cursor。以前的先 Google 搜索问题，然后阅读其他人编写的技术文章找到解法，这样的复杂过程已经彻底不用了。当我需要了解某个技术问题的原理、某个三方库的使用方法时，直接让 Cursor 给出教程、编写示例 即可。

<br/>

除了上面提到的两个场景之外，还有很多很多。

让我认识到，程序员还有很多事情可以做，未来并不是不再需要软件了，而是需要的更多。

旧软件正在经历更新换代，有很多开发工作要做。

### 2. 概率特性

当大家认识 AI 的概率本质之后，才能快速理解到它能干什么、不能干什么。

AI 不适合解决那些「对结果要求非常严格」的问题。

- ChatGPT 为什么那么成功。是因为对话场景本身对结果的要求就不那么严格。AI 只要能回答出来就行了，对错其实无所谓。只要大概率是正确的，那就是有用的，也就会有人来使用。类似的场景还有 智能客服、内容搜索 等。

- Cursor 为什么那么成功。我觉得也是如此，在某些特定场景，程序员对结果的要求也不是那么高。比如说 Tab 补全，它只要能大致推断出来就行了。就算不太对，立即人工改正就行。

<br/>

周围很多事情，对结果的要求也不高，即使它是用严谨的代码编写出来的。

比如说，我想翻译一篇文章、或者学习一个历史典故，就没有必要太准确。

又比如，创业者需要快速开发原型验证市场，也没必要太苛刻，差不多就足够了。

以上这些场景，使用 AI 就会有明显效果。

<br/>

但是也有另外一些场景，就不适合使用 AI。

比如说一些可能存在较高风险的场景，你也不希望所乘坐的飞机，导航系统是用 AI 写的吧，即使它通过了测试。

<br/>

提供足够多的上下文，可以能提升概率，却无法改变「它是一种概率」的本质。

所以上下文工程，其实在一定程度上掩盖了问题，它强行把结果与努力程度挂钩。

除此之外，提升概率是有代价的，也有极限，对结果正确性的要求越严格，成本就越高，就得考虑值不值得的问题了。

举个似乎不太恰当的例子，即使给出再多的上下文，对比 AI 两次生成的代码，也不可能完全一样。

### 3. 掌控 AI

认识到 AI 的概率本质之后，我们会不会对大模型感到失望呢？反而不会。

- 无数历史表明，当人们开始认识到工具的局限性之后，非但不会弃用工具，反而是能把它用得更好了。因为在迷信阶段人们会滥用工具，很多场景都用得不对，所以成效甚微。一旦破除了迷信，就能大幅度的降低成本，提升性价比，反而显得工具更加重要的了。

- 并且，一旦我们提升了认知，摸清了工具的局限和边界之后，看待问题的方式也就变了。我们会考虑，怎么转化问题，让 AI 可以解决它。或者拆分问题，让 AI 低成本的解决问题的一部分（想到 MCP 了）。

<br/>

回到 AI 编程，当 Cursor 总是无法准确的完成需求时，我们不再「只是」反思是否自己没有提供足够的上下文，是否自己用的不对。

还会考虑，原始问题是否真的适合用 AI 全部解决，能否换一种思路，让 AI 解决它擅长的部分。

比如说，即使一个完整的需求对实现方式的要求非常严格，也可以分成几个阶段。

或者先让 AI 去完成草图，再由人类精确调整。或者先让 AI 开发某些模块，再由人类拼起来。

这肯定会降低问题的原始复杂度，将问题转化成适合用 AI 解决的问题。

<br/>

AI 工具跟以往的其他工具，并没有什么太多的不同。

能被人类掌控，才是发展的第一步。

网上有很多文章，很少提及 AI 不好/不适合的场景，这是不完整的。

不适合也不一定不用它，知道哪里不适合反而才可以更好的使用它。

### 结语

从人类认识到 AI 的局限性，开始思考它的适用场景开始，才进入到 AI 的理性发展阶段。

在阅读相关资料和文章的时候，很多论点都是有意修饰过的，需要我们时刻保有自己的认知，最好的办法就是亲身实践。

当有了一个新概念、新趋势的时候，亲自去试试，而不是人云亦云，会发现很多事情不是传说的那样。

<br/>

当然未来 AI 如何发展，是不可预知的。

本文也只是对最近这段时间的 AI 使用，做了一些总结。

不排除这些观点以后有被推翻的可能，但认识的发展本来就是螺旋上升的。

即使理解错了，也能代表现在最成熟的想法。以此为基础更新迭代，仍然是有用的。

### 后记

最近随着 GPT 5.2 的发布，又一次加深了我的理解，

- 大模型幻觉问题确实无法根除，最聪明的模型，连[手指](https://36kr.com/p/3596739654156289)都数不清楚，你敢让这样的模型做手术吗。概率本质 +1

- 大模型之间的能力差距，已经小到可以忽略不计了。新模型再怎么吹牛，提升其实也没多大。边际效用递减 +1

- 互联网上 AI 生成的内容越来越多，再拿这些内容去训练新模型，幻觉问题肯定会更严重，大模型快要吃完「好内容」的红利了。「复读机」无法真正的「思考」 +1

<br/>

这不是说 AI 不行了，而是说它有局限性。

虽然有很多场景已经离不开 AI 了，但我们也不应该迷信广告，而是要看「疗效」。

<br/>

此外，AI 的发展前景，也不全是积极的，也有消极的一面。

这很明显，当前 Cursor 这么好用，是因为参考代码都是人写的。

等大部分的代码都是由 AI 生成乱写的时候，你猜它会给你推荐什么。
